{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self, demographic='all'):\n",
    "        if demographic == 'all':\n",
    "            self.train = pd.read_pickle('tweets-data/train.pkl')\n",
    "            self.test = pd.read_pickle('tweets-data/test.pkl')\n",
    "            self.dev = pd.read_pickle('tweets-data/dev.pkl')\n",
    "            self.unlabeled = pd.read_pickle('tweets-data/unlabeled.pkl')\n",
    "\n",
    "            self.train_tfidf = pd.read_pickle('tfidf/train_tfidf.pkl')\n",
    "            self.test_tfidf = pd.read_pickle('tfidf/test_tfidf.pkl')\n",
    "            self.dev_tfidf = pd.read_pickle('tfidf/dev_tfidf.pkl')\n",
    "            self.unlabeled_tfidf = pd.read_pickle('tfidf/unlabeled_tfidf.pkl')\n",
    "\n",
    "            self.train_emb = pd.read_pickle('sentence-transformers/train_emb.pkl')\n",
    "            self.test_emb = pd.read_pickle('sentence-transformers/test_emb.pkl')\n",
    "            self.dev_emb = pd.read_pickle('sentence-transformers/dev_emb.pkl')\n",
    "            self.unlabeled_emb = pd.read_pickle('sentence-transformers/unlabeled_emb.pkl')\n",
    "        else:\n",
    "            self.train = pd.read_pickle('tweets-data/train.pkl')[pd.read_pickle('tweets-data/train.pkl')['Demographic'] == demographic]\n",
    "            self.test = pd.read_pickle('tweets-data/test.pkl')[pd.read_pickle('tweets-data/test.pkl')['Demographic'] == demographic]\n",
    "            self.dev = pd.read_pickle('tweets-data/dev.pkl')[pd.read_pickle('tweets-data/dev.pkl')['Demographic'] == demographic]\n",
    "            self.unlabeled = pd.read_pickle('tweets-data/unlabeled.pkl')\n",
    "\n",
    "            self.train_tfidf = pd.read_pickle('tfidf/train_tfidf.pkl')[pd.read_pickle('tfidf/train_tfidf.pkl')['Demographic'] == demographic]\n",
    "            self.test_tfidf = pd.read_pickle('tfidf/test_tfidf.pkl')[pd.read_pickle('tfidf/test_tfidf.pkl')['Demographic'] == demographic]\n",
    "            self.dev_tfidf = pd.read_pickle('tfidf/dev_tfidf.pkl')[pd.read_pickle('tfidf/dev_tfidf.pkl')['Demographic'] == demographic]\n",
    "            self.unlabeled_tfidf = pd.read_pickle('tfidf/unlabeled_tfidf.pkl')\n",
    "\n",
    "            self.train_emb = pd.read_pickle('sentence-transformers/train_emb.pkl')[pd.read_pickle('sentence-transformers/train_emb.pkl')['Demographic'] == demographic]\n",
    "            self.test_emb = pd.read_pickle('sentence-transformers/test_emb.pkl')[pd.read_pickle('sentence-transformers/test_emb.pkl')['Demographic'] == demographic]\n",
    "            self.dev_emb = pd.read_pickle('sentence-transformers/dev_emb.pkl')[pd.read_pickle('sentence-transformers/dev_emb.pkl')['Demographic'] == demographic]\n",
    "            self.unlabeled_emb = pd.read_pickle('sentence-transformers/unlabeled_emb.pkl')\n",
    "        \n",
    "        # remove _twitter-entity_, set the text into lower case and a list of words\n",
    "        self.train['text'] = self.train['text'].str.lower().str.replace('_twitter-entity_','').str.split()\n",
    "        self.train['Length'] = self.train['text'].str.len()\n",
    "        \n",
    "        self.dev['text'] = self.dev['text'].str.lower().str.replace('_twitter-entity_','').str.split()\n",
    "        self.dev['Length'] = self.dev['text'].str.len()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dg = dataset()\n",
    "aae = dataset('AAE')\n",
    "sae = dataset('SAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def knn(demographic, dataset, test = False):\n",
    "    clf = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
    "    y = demographic.train['Sentiment']\n",
    "    dev_y = demographic.dev['Sentiment']\n",
    "    if dataset == 'tfidf':\n",
    "        x_tfidf = demographic.train_tfidf['TFIDF'].tolist()\n",
    "        clf.fit(x_tfidf, y)\n",
    "        result = clf.predict(demographic.dev_tfidf['TFIDF'].tolist())\n",
    "    if dataset == 'emb':\n",
    "        x_emb = demographic.train_emb['TFIDF'].tolist()\n",
    "        clf.fit(x_emb, y)\n",
    "        result = clf.predict(demographic.dev_emb['TFIDF'].tolist())\n",
    "    if test == True:\n",
    "        if dataset == 'tfidf':\n",
    "            result = clf.predict(demographic.test_tfidf['TFIDF'].tolist())\n",
    "        else:\n",
    "            result = clf.predict(demographic.test_emb['TFIDF'].tolist())\n",
    "    return result   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def gnb(demographic, dataset, prob = False, test=False):\n",
    "    clf = GaussianNB()\n",
    "    y = demographic.train['Sentiment']\n",
    "    dev_y = demographic.dev['Sentiment']\n",
    "    if dataset == 'tfidf':\n",
    "        x_tfidf = demographic.train_tfidf['TFIDF'].tolist()\n",
    "        clf.fit(x_tfidf, y)\n",
    "        if prob == True:\n",
    "            result = clf.predict_log_proba(demographic.dev_tfidf['TFIDF'].tolist())\n",
    "        else:\n",
    "            result = clf.predict(demographic.dev_tfidf['TFIDF'].tolist())\n",
    "    if dataset == 'emb':\n",
    "        x_emb = demographic.train_emb['TFIDF'].tolist()\n",
    "        clf.fit(x_emb, y)\n",
    "        if prob == True:\n",
    "            result = clf.predict_log_proba(demographic.dev_emb['TFIDF'].tolist())\n",
    "        else:\n",
    "            result = clf.predict(demographic.dev_emb['TFIDF'].tolist())\n",
    "    if test == True:\n",
    "        if dataset == 'tfidf':\n",
    "            result = clf.predict(demographic.test_tfidf['TFIDF'].tolist())\n",
    "        else:\n",
    "            result = clf.predict(demographic.test_emb['TFIDF'].tolist())\n",
    "    return result     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def lr(demographic, dataset, prob = False, test = False):\n",
    "    clf = LogisticRegression(max_iter=200)\n",
    "    y = demographic.train['Sentiment']\n",
    "    dev_y = demographic.dev['Sentiment']\n",
    "    if dataset == 'tfidf':\n",
    "        x_tfidf = demographic.train_tfidf['TFIDF'].tolist()\n",
    "        clf.fit(x_tfidf, y)\n",
    "        if prob == True:\n",
    "            result = clf.predict_proba(demographic.dev_tfidf['TFIDF'].tolist())\n",
    "        else:\n",
    "            result = clf.predict(demographic.dev_tfidf['TFIDF'].tolist())\n",
    "    if dataset == 'emb':\n",
    "        x_emb = demographic.train_emb['TFIDF'].tolist()\n",
    "        clf.fit(x_emb, y)\n",
    "        if prob == True:\n",
    "            result = clf.predict_proba(demographic.dev_emb['TFIDF'].tolist())\n",
    "        else:\n",
    "            result = clf.predict(demographic.dev_emb['TFIDF'].tolist())\n",
    "    if test == True:\n",
    "        if dataset == 'tfidf':\n",
    "            result = clf.predict(demographic.test_tfidf['TFIDF'].tolist())\n",
    "        else:\n",
    "            result = clf.predict(demographic.test_emb['TFIDF'].tolist())\n",
    "    return result       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "dataset = ['tfidf', 'emb']\n",
    "demographic = [aae, sae]\n",
    "dg_name = ['aae', 'sae']\n",
    "models = [knn, gnb, lr]\n",
    "model_names = ['KNN', 'GNB', 'LR']\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(model_names[i])\n",
    "    for j in range(len(demographic)):\n",
    "        class_y = demographic[j].dev['Sentiment']\n",
    "        print(dg_name[j])\n",
    "        for k in dataset:\n",
    "            print(k)\n",
    "            y_pred = models[i](demographic[j], k)\n",
    "            print(classification_report(class_y, y_pred, zero_division=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_evaluate(dataset):\n",
    "    aae_prob = lr(aae, dataset, True)\n",
    "    aae_pred_label = lr(aae, dataset)\n",
    "    aae_label = np.array(aae.dev['Sentiment'])\n",
    "    aae_prob = pd.DataFrame(aae_prob)\n",
    "    aae_pred_label = pd.DataFrame(aae_pred_label)\n",
    "    aae_label = pd.DataFrame(aae_label)\n",
    "    aae_prob = pd.concat([aae_prob, aae_pred_label, aae_label], axis=1)\n",
    "    aae_prob.columns = ['prob_neg', 'prob_pos', 'predictions', 'labels']\n",
    "\n",
    "    sae_prob = lr(sae, dataset, True)\n",
    "    sae_pred_label = lr(sae, dataset)\n",
    "    sae_label = np.array(sae.dev['Sentiment'])\n",
    "    sae_prob = pd.DataFrame(sae_prob)\n",
    "    sae_pred_label = pd.DataFrame(sae_pred_label)\n",
    "    sae_label = pd.DataFrame(sae_label)\n",
    "    sae_prob = pd.concat([sae_prob, sae_pred_label, sae_label], axis=1)\n",
    "    sae_prob.columns = ['prob_neg', 'prob_pos', 'predictions', 'labels']\n",
    "    \n",
    "    prob = [0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    aae_pos = []\n",
    "    aae_neg = []\n",
    "    aae_pos_num = []\n",
    "    aae_neg_num = []\n",
    "    for i in range(len(prob)):\n",
    "        if prob[i] == 1:\n",
    "            break\n",
    "        else:\n",
    "            pos_correct = aae_prob[(aae_prob['prob_pos'] > prob[i]) & (aae_prob['prob_pos'] <= prob[i+1]) & \n",
    "                                     (aae_prob['predictions'] == aae_prob['labels'])]\n",
    "            pos_prob = aae_prob[(aae_prob['prob_pos'] > prob[i]) & (aae_prob['prob_pos'] <= prob[i+1])]\n",
    "            aae_pos.append(len(pos_correct) / len(pos_prob))\n",
    "            aae_pos_num.append(len(pos_prob))\n",
    "\n",
    "            neg_correct = aae_prob[(aae_prob['prob_neg'] > prob[i]) & (aae_prob['prob_neg'] <= prob[i+1]) & \n",
    "                                     (aae_prob['predictions'] == aae_prob['labels'])]\n",
    "            neg_prob = aae_prob[(aae_prob['prob_neg'] > prob[i]) & (aae_prob['prob_neg'] <= prob[i+1])]\n",
    "            aae_neg.append(len(neg_correct) / len(neg_prob))\n",
    "            aae_neg_num.append(len(neg_prob))\n",
    "\n",
    "    sae_pos = []\n",
    "    sae_neg = []\n",
    "    sae_pos_num = []\n",
    "    sae_neg_num = []\n",
    "    for i in range(len(prob)):\n",
    "        if prob[i] == 1:\n",
    "            break\n",
    "        else:\n",
    "            pos_correct = sae_prob[(sae_prob['prob_pos'] > prob[i]) & (sae_prob['prob_pos'] <= prob[i+1]) & \n",
    "                                     (sae_prob['predictions'] == sae_prob['labels'])]\n",
    "            pos_prob = sae_prob[(sae_prob['prob_pos'] > prob[i]) & (sae_prob['prob_pos'] <= prob[i+1])]\n",
    "            sae_pos.append(len(pos_correct) / len(pos_prob))\n",
    "            sae_pos_num.append(len(pos_prob))\n",
    "            neg_correct = sae_prob[(sae_prob['prob_neg'] > prob[i]) & (sae_prob['prob_neg'] <= prob[i+1]) & \n",
    "                                     (sae_prob['predictions'] == sae_prob['labels'])]\n",
    "            neg_prob = sae_prob[(sae_prob['prob_neg'] > prob[i]) & (sae_prob['prob_neg'] <= prob[i+1])]\n",
    "            sae_neg.append(len(neg_correct) / len(neg_prob))\n",
    "            sae_neg_num.append(len(neg_prob))\n",
    "            \n",
    "    plt.plot(aae_pos)\n",
    "    plt.plot(aae_neg)\n",
    "    plt.plot(sae_pos)\n",
    "    plt.plot(sae_neg)\n",
    "    plt.legend(['aae_pos', 'aae_neg', 'sae_pos', 'sae_neg'])\n",
    "    plt.xticks(range(5))\n",
    "    plt.title('Range of Prediction Accuracies')\n",
    "    plt.xlabel('Ranges\\n(0=0.5-0.6, 1=0.6-0.7, 2=0.7-0.8, 3=0.8-0.9, 4=0.9-1)')\n",
    "    plt.ylabel('Accuracy Proportion')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(aae_pos_num)\n",
    "    plt.plot(aae_neg_num)\n",
    "    plt.plot(sae_pos_num)\n",
    "    plt.plot(sae_neg_num)\n",
    "    plt.legend(['aae_pos', 'aae_neg', 'sae_pos', 'sae_neg'])\n",
    "    plt.xticks(range(5))\n",
    "    plt.title('Number of the Range of Prediction Confidence')\n",
    "    plt.xlabel('Ranges\\n(0=0.5-0.6, 1=0.6-0.7, 2=0.7-0.8, 3=0.8-0.9, 4=0.9-1)')\n",
    "    plt.ylabel('Numbers')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression tfidf')\n",
    "lr_evaluate('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression emb')\n",
    "lr_evaluate('emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(demographic):\n",
    "    pos_set = []\n",
    "    for i in demographic['text']:\n",
    "        tags = nltk.pos_tag(i, tagset='universal')\n",
    "        num_pos = {}\n",
    "        for j in tags:\n",
    "            num_pos[j[1]] = num_pos.get(j[1], 0) + 1\n",
    "        pos_set.append(num_pos)\n",
    "    pos_set = pd.DataFrame(pos_set)\n",
    "    pos_set = pos_set.fillna(0)\n",
    "    \n",
    "    length = np.array(demographic['Length'])\n",
    "    length = pd.DataFrame(length)\n",
    "    length.columns = ['Length']\n",
    "    addition_set = pd.concat([pos_set,length], axis=1)\n",
    "    return addition_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aae\n",
    "y = aae.train['Sentiment']\n",
    "pos_aae = pos(aae.train)\n",
    "mi = mutual_info_classif(pos_aae, y,discrete_features=True)\n",
    "for i in range(13):\n",
    "    print(pos_aae.columns[i],':', mi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sae\n",
    "y = sae.train['Sentiment']\n",
    "pos_sae = pos(sae.train)\n",
    "mi = mutual_info_classif(pos_sae, y,discrete_features=True)\n",
    "for i in range(13):\n",
    "    print(pos_sae.columns[i],':', mi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 5 pos features and length with the most correlation\n",
    "key_pos = ['NOUN', 'VERB', 'ADV', 'PRT', 'Length']\n",
    "pos_aae_train = pos(aae.train)\n",
    "pos_aae_train.index = aae.train.index\n",
    "pos_sae_train = pos(sae.train)\n",
    "pos_sae_train.index = sae.train.index\n",
    "\n",
    "\n",
    "pos_aae_dev = pos(aae.dev)\n",
    "pos_aae_dev.index = aae.dev.index\n",
    "pos_sae_dev = pos(sae.dev)\n",
    "pos_sae_dev.index = sae.dev.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model using pos as features\n",
    "def pos_model(model, dg):\n",
    "    if model == 'knn':\n",
    "        clf = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
    "    elif model == 'gnb':\n",
    "        clf = GaussianNB()\n",
    "    else:\n",
    "        clf = LogisticRegression(max_iter=200)\n",
    "        \n",
    "    y = dg.train['Sentiment']\n",
    "    dev_y = dg.dev['Sentiment']\n",
    "    print(model)\n",
    "    if dg == aae:\n",
    "        print('aae')\n",
    "        clf.fit(pos_aae_train, y)\n",
    "        \n",
    "        prediction = clf.predict(pos_aae_dev)\n",
    "        score = classification_report(prediction, dev_y, zero_division=0)\n",
    "    else:\n",
    "        print('sae')\n",
    "        clf.fit(pos_sae_train, y)\n",
    "        prediction = clf.predict(pos_sae_dev)\n",
    "        score = classification_report(prediction, dev_y, zero_division=0)   \n",
    "    print(score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#scores\n",
    "pos_model('knn', aae)\n",
    "pos_model('knn', sae)\n",
    "pos_model('gnb', aae)\n",
    "pos_model('gnb', sae)\n",
    "pos_model('lr', aae)\n",
    "pos_model('lr', sae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
